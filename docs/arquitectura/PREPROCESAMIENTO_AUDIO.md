# Pipeline de Preprocesamiento de Audio

## üéØ Resumen Ejecutivo

Cada m√≥dulo del sistema aplica su propio preprocesamiento especializado al audio antes de la inferencia. Aunque comparten operaciones comunes (resample, mono conversion, normalizaci√≥n), cada m√≥dulo tiene requisitos espec√≠ficos seg√∫n su arquitectura de red neuronal.

---

## üìä Visi√≥n General del Flujo

```
Audio Bytes (Input)
    ‚Üì
[Conversi√≥n a Tensor] ‚Üí BytesIO ‚Üí torchaudio.load()
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           PREPROCESAMIENTO COM√öN (3 M√ìDULOS)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Resample a 16 kHz                                       ‚îÇ
‚îÇ  2. Conversi√≥n a Mono                                       ‚îÇ
‚îÇ  3. Normalizaci√≥n de Amplitud                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Antispoofing‚îÇ Speaker Recognition‚îÇ Text Verification‚îÇ
‚îÇ (AASIST +   ‚îÇ (ECAPA-TDNN)      ‚îÇ (Wav2Vec2)        ‚îÇ
‚îÇ RawNet2)    ‚îÇ                   ‚îÇ                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üî¨ M√≥dulo 1: Antispoofing (AASIST + RawNet2)

### Archivo: `SpoofDetectorAdapter.py`

### Par√°metros de Configuraci√≥n:
```python
target_sample_rate = 16000  # Hz
device = "cuda" o "cpu"
```

### Pipeline de Preprocesamiento:

#### 1. **Carga de Audio**
```python
audio_io = io.BytesIO(audio_data)
waveform, sample_rate = torchaudio.load(audio_io)
```
- **Input:** Bytes del archivo de audio
- **Output:** Tensor de waveform + sample rate original

#### 2. **Resampling (si necesario)**
```python
if sample_rate != 16000:
    resampler = torchaudio.transforms.Resample(sample_rate, 16000)
    waveform = resampler(waveform)
```
- **Objetivo:** Estandarizar a 16 kHz (requerido por modelos)
- **M√©todo:** Interpolaci√≥n de torchaudio
- **Output:** Waveform a 16 kHz

#### 3. **Conversi√≥n a Mono**
```python
if waveform.shape[0] > 1:
    waveform = torch.mean(waveform, dim=0, keepdim=True)
```
- **Objetivo:** Reducir canales est√©reo a mono
- **M√©todo:** Promedio de canales
- **Output:** Waveform mono `[1, samples]`

#### 4. **Transferencia a Device**
```python
waveform = waveform.to(self.device)
```
- **Objetivo:** Mover tensor a GPU o CPU seg√∫n configuraci√≥n
- **Output:** Tensor en device objetivo

### Caracter√≠sticas Especiales:
- ‚úÖ **Sin truncamiento:** Acepta audios de longitud variable
- ‚úÖ **Sin padding:** Los modelos manejan longitud variable
- ‚úÖ **Sin normalizaci√≥n expl√≠cita:** Los modelos esperan valores raw

### Output Final:
```python
torch.Tensor: shape [1, samples], dtype float32, range [-1, 1]
```

---

## üé§ M√≥dulo 2: Speaker Recognition (ECAPA-TDNN)

### Archivo: `SpeakerEmbeddingAdapter.py`

### Par√°metros de Configuraci√≥n:
```python
target_sample_rate = 16000  # Hz
target_length = 3.0  # seconds (referencia, no forzado)
MIN_AUDIO_DURATION_SEC = 1.0  # M√≠nimo aceptable
MAX_AUDIO_DURATION_SEC = 10.0  # M√°ximo aceptable
```

### Pipeline de Preprocesamiento:

#### 1. **Conversi√≥n de Formato (si necesario)**
```python
if format_lower != "wav":
    audio_data = convert_to_wav(audio_data, format_lower)
```
- **Objetivo:** Convertir MP3, OGG, etc. a WAV
- **Herramienta:** `audio_converter.py` (usa pydub)
- **Output:** Audio en formato WAV

#### 2. **Carga de Audio WAV**
```python
waveform, sample_rate = self._load_wav_audio(audio_data)
```
- **M√©todo:** `wave` library o torchaudio
- **Output:** NumPy array + sample rate

#### 3. **Resampling (si necesario)**
```python
if sample_rate != 16000:
    waveform = torchaudio.functional.resample(
        torch.tensor(waveform), 
        orig_freq=sample_rate, 
        new_freq=16000
    ).numpy()
```
- **Objetivo:** Estandarizar a 16 kHz
- **Output:** Waveform a 16 kHz

#### 4. **Conversi√≥n a Mono**
```python
if len(waveform.shape) > 1:
    waveform = np.mean(waveform, axis=0)
```
- **M√©todo:** Promedio de canales (NumPy)
- **Output:** Array 1D

#### 5. **Normalizaci√≥n de Amplitud**
```python
waveform = waveform / (np.max(np.abs(waveform)) + 1e-8)
```
- **Objetivo:** Escalar a rango [-1, 1]
- **M√©todo:** Divisi√≥n por valor m√°ximo absoluto
- **Epsilon:** 1e-8 para evitar divisi√≥n por cero
- **Output:** Waveform normalizado

#### 6. **Ajuste de Longitud (Trim/Pad)**
```python
max_samples = int(10.0 * sample_rate)  # 10s max
min_samples = int(1.0 * sample_rate)   # 1s min

if len(waveform) > max_samples:
    # Trim: tomar porci√≥n central
    start = (len(waveform) - max_samples) // 2
    waveform = waveform[start:start + max_samples]
    
elif len(waveform) < min_samples:
    # Pad: rellenar con ceros
    pad_length = min_samples - len(waveform)
    waveform = np.pad(waveform, (0, pad_length), mode='constant')
```
- **Trim:** Si > 10s, tomar porci√≥n central de 10s
- **Pad:** Si < 1s, rellenar con ceros hasta 1s
- **Mantener:** Si entre 1s y 10s, dejar sin modificar

### Caracter√≠sticas Especiales:
- ‚úÖ **Longitud variable:** Acepta entre 1s y 10s
- ‚úÖ **Normalizaci√≥n obligatoria:** Cr√≠tico para ECAPA-TDNN
- ‚úÖ **Centro del audio:** Al truncar, toma la parte central (mejor calidad)

### Output Final:
```python
np.ndarray: shape [samples], dtype float32, range [-1, 1]
Samples: entre 16,000 (1s) y 160,000 (10s)
```

---

## üó£Ô∏è M√≥dulo 3: Text Verification (Wav2Vec2 ASR)

### Archivo: `ASRAdapter.py`

### Par√°metros de Configuraci√≥n:
```python
target_sample_rate = 16000  # Hz
max_asr_samples = int(15.0 * 16000)  # 15 segundos m√°ximo
```

### Pipeline de Preprocesamiento:

#### 1. **Carga de Audio**
```python
audio_io = io.BytesIO(audio_data)
waveform, sample_rate = torchaudio.load(audio_io)
```
- **Input:** Bytes del archivo de audio
- **Output:** Tensor de waveform + sample rate

#### 2. **Resampling (si necesario)**
```python
if sample_rate != 16000:
    resampler = torchaudio.transforms.Resample(sample_rate, 16000)
    waveform = resampler(waveform)
    sample_rate = 16000
```
- **Objetivo:** Estandarizar a 16 kHz
- **Output:** Waveform a 16 kHz

#### 3. **Conversi√≥n a Mono**
```python
if waveform.shape[0] > 1:
    waveform = torch.mean(waveform, dim=0, keepdim=True)
```
- **M√©todo:** Promedio de canales
- **Output:** Waveform mono `[1, samples]`

#### 4. **Truncamiento (IMPORTANTE)**
```python
max_asr_samples = int(15.0 * sample_rate)  # 240,000 samples
if waveform.shape[1] > max_asr_samples:
    waveform = waveform[:, :max_asr_samples]  # Tomar inicio
```
- **Objetivo:** Limitar a 15 segundos (optimizaci√≥n de rendimiento)
- **M√©todo:** Truncar al inicio (no centro)
- **Raz√≥n:** Bug fix cr√≠tico - antes limitaba a 5s causando WER 60%
- **Output:** M√°ximo 15s de audio

#### 5. **Normalizaci√≥n de Amplitud**
```python
max_val = waveform.abs().max()
if max_val > 0:
    waveform = waveform / max_val
```
- **Objetivo:** Escalar a rango [-1, 1]
- **M√©todo:** Divisi√≥n por valor m√°ximo absoluto
- **Output:** Waveform normalizado

#### 6. **Transferencia a Device**
```python
waveform = waveform.to(self.device)
```
- **Objetivo:** Mover a GPU/CPU
- **Output:** Tensor en device objetivo

### Caracter√≠sticas Especiales:
- ‚úÖ **L√≠mite de 15s:** Optimizaci√≥n cr√≠tica para ASR
- ‚úÖ **Truncar desde inicio:** Mejor para frases cortas al principio
- ‚úÖ **Sin padding:** ASR maneja longitud variable
- ‚ö†Ô∏è **Bug hist√≥rico:** Antes limitaba a 5s (causaba WER 60% ‚Üí 8%)

### Output Final:
```python
torch.Tensor: shape [1, samples], dtype float32, range [-1, 1]
Samples: m√°ximo 240,000 (15s a 16kHz)
```

---

## üìã Tabla Comparativa de Preprocesamiento

| Operaci√≥n | Antispoofing | Speaker Recognition | Text Verification |
|-----------|--------------|---------------------|-------------------|
| **Sample Rate** | 16 kHz | 16 kHz | 16 kHz |
| **Resample** | ‚úÖ Si necesario | ‚úÖ Si necesario | ‚úÖ Si necesario |
| **Mono Conversion** | ‚úÖ Promedio | ‚úÖ Promedio | ‚úÖ Promedio |
| **Normalizaci√≥n** | ‚ùå No | ‚úÖ S√≠ (max abs) | ‚úÖ S√≠ (max abs) |
| **Truncamiento** | ‚ùå No | ‚úÖ 10s (centro) | ‚úÖ 15s (inicio) |
| **Padding** | ‚ùå No | ‚úÖ Si < 1s | ‚ùå No |
| **Output Type** | torch.Tensor | np.ndarray | torch.Tensor |
| **Output Shape** | `[1, samples]` | `[samples]` | `[1, samples]` |
| **Device** | GPU/CPU | CPU (NumPy) | GPU/CPU |

---

## üîß Operaciones Comunes Detalladas

### 1. Resample (Todos los m√≥dulos)
```python
# M√©todo: Resampler de torchaudio
resampler = torchaudio.transforms.Resample(
    orig_freq=sample_rate_original,
    new_freq=16000
)
waveform_resampled = resampler(waveform)
```
- **Algoritmo:** Interpolaci√≥n sinc (alta calidad)
- **Preserva:** Informaci√≥n espectral dentro de Nyquist
- **Costo:** ~10-20ms por segundo de audio

### 2. Conversi√≥n a Mono (Todos los m√≥dulos)
```python
# M√©todo: Promedio aritm√©tico de canales
waveform_mono = torch.mean(waveform, dim=0, keepdim=True)
# o en NumPy:
waveform_mono = np.mean(waveform, axis=0)
```
- **Por qu√© promedio:** Preserva energ√≠a total
- **Alternativas:** Tomar solo canal izquierdo (m√°s r√°pido, menos robusto)

### 3. Normalizaci√≥n de Amplitud (Speaker + ASR)
```python
# M√©todo 1: Max absolute scaling (usado en el sistema)
waveform_norm = waveform / (waveform.abs().max() + epsilon)

# M√©todo 2: RMS normalization (alternativa com√∫n)
rms = torch.sqrt(torch.mean(waveform ** 2))
waveform_norm = waveform / (rms + epsilon)
```
- **Max abs:** Mantiene din√°mica original, escala lineal
- **RMS:** Iguala energ√≠a promedio, mejor para audios con silencio

---

## ‚ö° Optimizaciones de Performance

### 1. Lazy Loading de Modelos
```python
# Los modelos se cargan solo la primera vez
if not self._model_loaded:
    self._load_model()
```
- **Ahorro:** ~2-5 segundos en inicio

### 2. Device Caching
```python
# Tensors permanecen en GPU entre inferencias
waveform = waveform.to(self.device)
```
- **Ahorro:** ~5-10ms por transferencia CPU‚ÜíGPU

### 3. Batch Processing Potencial
```python
# Los modelos soportan batching
with torch.no_grad():
    scores = model.classify_batch(waveform)
```
- **Escalabilidad:** Procesamiento paralelo de m√∫ltiples audios

### 4. Thread Safety
```python
with self._lock:
    prediction = self._model.predict(waveform)
```
- **Protecci√≥n:** Evita race conditions en requests concurrentes

---

## üêõ Bugs Hist√≥ricos y Fixes

### Bug #1: ASR Truncamiento a 5s (CR√çTICO)
**Problema:**
```python
# ANTES (causaba WER 60%)
max_asr_samples = int(5.0 * sample_rate)
start = (waveform.shape[1] - max_asr_samples) // 2  # Centro
waveform = waveform[:, start:start+max_asr_samples]
```

**Fix Aplicado:**
```python
# DESPU√âS (WER 8%)
max_asr_samples = int(15.0 * sample_rate)
waveform = waveform[:, :max_asr_samples]  # Inicio
```

**Impacto:**
- WER: 59.98% ‚Üí 8.26%
- Genuinos aceptados: 2.8% ‚Üí 80.6%
- **Root cause:** Frases del dataset son cortas, estaban al inicio del audio

---

## üìä M√©tricas de Preprocesamiento

### Tiempo de Procesamiento (Promedio por audio de 3s):
| Operaci√≥n | Antispoofing | Speaker | ASR |
|-----------|--------------|---------|-----|
| Load | ~5ms | ~5ms | ~5ms |
| Resample | ~10ms | ~10ms | ~10ms |
| Mono | ~2ms | ~2ms | ~2ms |
| Normalize | N/A | ~3ms | ~3ms |
| Trim/Pad | N/A | ~2ms | ~2ms |
| **Total** | **~17ms** | **~22ms** | **~22ms** |

### Memoria (por audio de 3s a 16kHz):
- **Waveform crudo:** 48,000 samples √ó 4 bytes = 192 KB
- **Tensor GPU:** 192 KB + overhead PyTorch (~50 KB) = ~240 KB
- **Batch de 10 audios:** ~2.4 MB (manejable en GPU)

---

## üîç Validaci√≥n de Preprocesamiento

### Tests Unitarios Sugeridos:

#### 1. **Test de Sample Rate**
```python
def test_resample_accuracy():
    audio_44100 = generate_test_audio(sample_rate=44100)
    audio_16000 = preprocess(audio_44100)
    assert audio_16000.sample_rate == 16000
```

#### 2. **Test de Mono Conversion**
```python
def test_stereo_to_mono():
    audio_stereo = generate_stereo_audio()
    audio_mono = preprocess(audio_stereo)
    assert audio_mono.shape[0] == 1
```

#### 3. **Test de Normalizaci√≥n**
```python
def test_normalization_range():
    audio = preprocess(raw_audio)
    assert audio.abs().max() <= 1.0
```

#### 4. **Test de Truncamiento**
```python
def test_asr_max_length():
    audio_20s = generate_long_audio(duration=20.0)
    processed = asr_adapter._preprocess_audio(audio_20s)
    assert processed.shape[1] <= 240000  # 15s max
```

---

## üìö Referencias

### C√≥digo Fuente:
- **Antispoofing:** `src/infrastructure/biometrics/SpoofDetectorAdapter.py` (l√≠neas 311-330)
- **Speaker Recognition:** `src/infrastructure/biometrics/SpeakerEmbeddingAdapter.py` (l√≠neas 167-230)
- **Text Verification:** `src/infrastructure/biometrics/ASRAdapter.py` (l√≠neas 180-215)

### Librer√≠as Utilizadas:
- **torchaudio:** v2.0+ para carga y resample
- **torch:** v2.0+ para operaciones de tensor
- **numpy:** v1.24+ para arrays en Speaker Recognition
- **wave:** stdlib para lectura WAV b√°sica

### Configuraci√≥n de Audio:
```python
# Constants en biometric_constants.py
EMBEDDING_DIMENSION = 192
MIN_AUDIO_DURATION_SEC = 1.0
MAX_AUDIO_DURATION_SEC = 10.0
```

---

## üéì Conclusi√≥n

El sistema implementa **preprocesamiento especializado por m√≥dulo**, con operaciones comunes pero par√°metros adaptados a cada arquitectura de red neuronal:

- **Antispoofing:** M√≠nimo procesamiento, modelos manejan variabilidad
- **Speaker Recognition:** Normalizaci√≥n estricta, longitud controlada (1-10s)
- **Text Verification:** Truncamiento a 15s, normalizaci√≥n para mejor transcripci√≥n

Todas las transformaciones son **determin√≠sticas y reproducibles**, garantizando consistencia entre enrollment y verification.
