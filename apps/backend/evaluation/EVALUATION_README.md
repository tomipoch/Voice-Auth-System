# Sistema de EvaluaciÃ³n del Sistema BiomÃ©trico de Voz

Este directorio contiene **4 scripts** enfocados para evaluar el sistema completo de autenticaciÃ³n biomÃ©trica por voz.

## ğŸ“‹ Ãndice de Scripts

1. **`evaluate_speaker_recognition.py`** - MÃ³dulo de Reconocimiento de Locutor
2. **`evaluate_text_verification.py`** - MÃ³dulo de VerificaciÃ³n de Texto (ASR)
3. **`evaluate_antispoofing.py`** - MÃ³dulo de Anti-Spoofing
4. **`evaluate_complete_system.py`** - Sistema Completo (MÃ©tricas de IntegraciÃ³n)

---

## ğŸ¯ 1. EvaluaciÃ³n del Reconocimiento de Locutor

**Script:** `evaluate_speaker_recognition.py`

### MÃ©tricas Calculadas

| MÃ©trica | DescripciÃ³n | InterpretaciÃ³n |
|---------|-------------|----------------|
| **FRR** (False Rejection Rate) | % de usuarios genuinos rechazados | âœ… Menor es mejor (~0% Ã³ptimo) |
| **FAR** (False Acceptance Rate) | % de impostores aceptados | âœ… Menor es mejor (~0% Ã³ptimo) |
| **EER** (Equal Error Rate) | Punto donde FAR = FRR | âœ… Menor es mejor (~0% Ã³ptimo) |

### Estructura del Dataset

```
evaluation/dataset/speaker_recognition/
  â”œâ”€â”€ enrollment/
  â”‚   â”œâ”€â”€ user1/
  â”‚   â”‚   â”œâ”€â”€ sample1.wav
  â”‚   â”‚   â”œâ”€â”€ sample2.wav
  â”‚   â”‚   â””â”€â”€ sample3.wav
  â”‚   â””â”€â”€ user2/
  â”‚       â””â”€â”€ ...
  â”œâ”€â”€ genuine/
  â”‚   â”œâ”€â”€ user1/
  â”‚   â”‚   â”œâ”€â”€ test1.wav
  â”‚   â”‚   â””â”€â”€ test2.wav
  â”‚   â””â”€â”€ user2/
  â”‚       â””â”€â”€ ...
  â””â”€â”€ impostor/
      â”œâ”€â”€ user1_vs_user2.wav
      â”œâ”€â”€ user1_vs_user3.wav
      â””â”€â”€ ...
```

### Uso

```bash
cd apps/backend
python evaluation/evaluate_speaker_recognition.py
```

### Salida

- Reporte: `evaluation/results/speaker_recognition_evaluation.txt`
- MÃ©tricas JSON: `evaluation/results/speaker_recognition_evaluation.json`

---

## ğŸ“ 2. EvaluaciÃ³n de VerificaciÃ³n de Texto

**Script:** `evaluate_text_verification.py`

### MÃ©tricas Calculadas

| MÃ©trica | DescripciÃ³n | InterpretaciÃ³n |
|---------|-------------|----------------|
| **WER** (Word Error Rate) | % de errores en palabras | âœ… Menor es mejor (~0% Ã³ptimo) |
| **Transcription Accuracy** | % de transcripciones correctas | âœ… Mayor es mejor (~100% Ã³ptimo) |
| **Phrase Matching Accuracy** | % de frases correctamente identificadas | âœ… Mayor es mejor (~100% Ã³ptimo) |

### Estructura del Dataset

```
evaluation/dataset/text_verification/
  â”œâ”€â”€ transcription_tests.json
  â”œâ”€â”€ phrase_matching_tests.json
  â”œâ”€â”€ audio1.wav
  â”œâ”€â”€ audio2.wav
  â””â”€â”€ ...
```

**Formato `transcription_tests.json`:**
```json
[
  {
    "audio": "audio1.wav",
    "text": "el texto esperado de la transcripciÃ³n"
  },
  {
    "audio": "audio2.wav",
    "text": "otra frase de ejemplo"
  }
]
```

**Formato `phrase_matching_tests.json`:**
```json
[
  {
    "audio": "audio1.wav",
    "expected_phrase": "la frase correcta",
    "test_phrases": [
      "la frase correcta",
      "otra frase diferente",
      "frase incorrecta"
    ]
  }
]
```

### Uso

```bash
cd apps/backend
python evaluation/evaluate_text_verification.py
```

### Salida

- Reporte: `evaluation/results/text_verification_evaluation.txt`
- MÃ©tricas JSON: `evaluation/results/text_verification_evaluation.json`

---

## ğŸ›¡ï¸ 3. EvaluaciÃ³n de Anti-Spoofing

**Script:** `evaluate_antispoofing.py`

### MÃ©tricas Calculadas (ISO/IEC 30107-3)

| MÃ©trica | DescripciÃ³n | InterpretaciÃ³n |
|---------|-------------|----------------|
| **APCER** (Attack Presentation Classification Error Rate) | % de ataques aceptados | âœ… Menor es mejor (~0% Ã³ptimo) |
| **BPCER** (Bona Fide Presentation Classification Error Rate) | % de genuinos rechazados | âœ… Menor es mejor (~0% Ã³ptimo) |
| **ACER** (Average Classification Error Rate) | Promedio de APCER y BPCER | âœ… Menor es mejor (~0% Ã³ptimo) |

### Estructura del Dataset

```
evaluation/dataset/antispoofing/
  â”œâ”€â”€ genuine/
  â”‚   â”œâ”€â”€ genuine1.wav
  â”‚   â”œâ”€â”€ genuine2.wav
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ tts/
  â”‚   â”œâ”€â”€ tts_attack1.wav
  â”‚   â”œâ”€â”€ tts_attack2.wav
  â”‚   â””â”€â”€ ...
  â””â”€â”€ cloning/
      â”œâ”€â”€ clone_attack1.wav
      â”œâ”€â”€ clone_attack2.wav
      â””â”€â”€ ...
```

### Uso

```bash
cd apps/backend
python evaluation/evaluate_antispoofing.py
```

### Salida

- Reporte: `evaluation/results/antispoofing_evaluation.txt`
- MÃ©tricas JSON: `evaluation/results/antispoofing_evaluation.json`
- MÃ©tricas separadas por tipo de ataque (TTS, Cloning)

---

## ğŸ”§ 4. EvaluaciÃ³n del Sistema Completo

**Script:** `evaluate_complete_system.py`

### MÃ©tricas Calculadas

#### Eficiencia

| MÃ©trica | DescripciÃ³n | InterpretaciÃ³n |
|---------|-------------|----------------|
| **RTF** (Real-Time Factor) | Tiempo de procesamiento / DuraciÃ³n del audio | âœ… Menor es mejor (~0 Ã³ptimo, <1 es tiempo real) |
| **TTP** (Total Processing Time) | Tiempo total de procesamiento en segundos | âœ… ~2 segundos es BUENO |

#### Robustez

| MÃ©trica | DescripciÃ³n | InterpretaciÃ³n |
|---------|-------------|----------------|
| **SNR vs Error** | Error de verificaciÃ³n segÃºn nivel de SNR | Menor error con SNR bajo es mejor |
| **Sensibilidad a DuraciÃ³n** | EER segÃºn duraciÃ³n del audio | EER bajo incluso con audio corto es mejor |

#### CalibraciÃ³n

| MÃ©trica | DescripciÃ³n | InterpretaciÃ³n |
|---------|-------------|----------------|
| **t-DCF** (tandem Detection Cost Function) | Costo de detecciÃ³n combinado | âœ… Menor es mejor (~0% Ã³ptimo) |

### Estructura del Dataset

```
evaluation/dataset/complete_system/
  â”œâ”€â”€ efficiency_test/
  â”‚   â”œâ”€â”€ audio1.wav
  â”‚   â”œâ”€â”€ audio2.wav
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ snr_robustness/
  â”‚   â”œâ”€â”€ genuine/
  â”‚   â”‚   â”œâ”€â”€ high_snr_audio.wav
  â”‚   â”‚   â”œâ”€â”€ medium_snr_audio.wav
  â”‚   â”‚   â””â”€â”€ low_snr_audio.wav
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ duration_sensitivity/
  â”‚   â”œâ”€â”€ genuine/
  â”‚   â”‚   â”œâ”€â”€ short_audio.wav
  â”‚   â”‚   â”œâ”€â”€ medium_audio.wav
  â”‚   â”‚   â””â”€â”€ long_audio.wav
  â”‚   â””â”€â”€ spoof/
  â”‚       â””â”€â”€ ...
  â””â”€â”€ antispoofing/
      â”œâ”€â”€ genuine/
      â”‚   â””â”€â”€ ...
      â””â”€â”€ spoof/
          â””â”€â”€ ...
```

### Uso

```bash
cd apps/backend
python evaluation/evaluate_complete_system.py
```

### Salida

- Reporte: `evaluation/results/complete_system_evaluation.txt`
- MÃ©tricas JSON: `evaluation/results/complete_system_evaluation.json`

---

## ğŸ“Š Resumen de Todas las MÃ©tricas

### Por MÃ³dulo

| MÃ³dulo | MÃ©tricas | Objetivo |
|--------|----------|----------|
| **Speaker Recognition** | FRR, FAR, EER | Todos cercanos a 0% |
| **Text Verification** | WER (~0%), Phrase Matching (~100%), Transcription (~100%) | WER bajo, Accuracy alto |
| **Anti-Spoofing** | APCER, BPCER, ACER | Todos cercanos a 0% |
| **Sistema Completo** | RTF (~0), TTP (~2s), SNR vs Error, DuraciÃ³n vs EER, t-DCF (~0) | Eficiente y robusto |

### InterpretaciÃ³n de Resultados

#### âœ… EXCELENTE
- FRR < 5%, FAR < 1%, EER < 5%
- WER < 5%, Transcription > 95%, Phrase Matching > 95%
- APCER < 5%, BPCER < 5%, ACER < 5%
- RTF < 0.5, TTP 1.5-3.0s, t-DCF < 0.05

#### âœ“ BUENO
- FRR < 10%, FAR < 5%, EER < 10%
- WER < 15%, Transcription > 85%, Phrase Matching > 85%
- APCER < 15%, BPCER < 15%, ACER < 15%
- RTF < 1.0, TTP < 5s, t-DCF < 0.10

#### âš ï¸ REQUIERE MEJORA
- FRR > 10%, FAR > 5%, EER > 10%
- WER > 15%, Transcription < 85%, Phrase Matching < 85%
- APCER > 15%, BPCER > 15%, ACER > 15%
- RTF > 1.0, TTP > 5s, t-DCF > 0.10

---

## ğŸš€ EjecuciÃ³n Completa

Para ejecutar todos los scripts en secuencia:

```bash
cd apps/backend

# 1. Speaker Recognition
python evaluation/evaluate_speaker_recognition.py

# 2. Text Verification
python evaluation/evaluate_text_verification.py

# 3. Anti-Spoofing
python evaluation/evaluate_antispoofing.py

# 4. Sistema Completo
python evaluation/evaluate_complete_system.py
```

---

## ğŸ“ Resultados

Todos los resultados se guardan en:

```
evaluation/results/
  â”œâ”€â”€ speaker_recognition_evaluation.txt
  â”œâ”€â”€ speaker_recognition_evaluation.json
  â”œâ”€â”€ text_verification_evaluation.txt
  â”œâ”€â”€ text_verification_evaluation.json
  â”œâ”€â”€ antispoofing_evaluation.txt
  â”œâ”€â”€ antispoofing_evaluation.json
  â”œâ”€â”€ complete_system_evaluation.txt
  â””â”€â”€ complete_system_evaluation.json
```

---

## ğŸ”§ Requisitos

- Python 3.8+
- Dependencias instaladas: `pip install -r requirements.txt`
- GPU recomendada para mejor rendimiento
- Datasets preparados en las rutas especificadas

---

## ğŸ“ Notas

- Los scripts son independientes y pueden ejecutarse en cualquier orden
- Los archivos `.txt` contienen reportes legibles para humanos
- Los archivos `.json` contienen mÃ©tricas estructuradas para procesamiento automÃ¡tico
- Todos los scripts incluyen logging detallado del progreso
- Los datasets de ejemplo deben ser proporcionados segÃºn las estructuras especificadas

---

## ğŸ“š Referencias

- **ISO/IEC 19795**: EstÃ¡ndares para evaluaciÃ³n de rendimiento biomÃ©trico
- **ISO/IEC 30107-3**: EstÃ¡ndares para mÃ©tricas de anti-spoofing
- **ASVspoof Challenge**: MetodologÃ­as de evaluaciÃ³n de anti-spoofing
