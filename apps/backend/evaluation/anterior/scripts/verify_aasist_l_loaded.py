"""
Verificar que AASIST-L se cargue correctamente desde archivos locales.
"""

import sys
from pathlib import Path

backend_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_dir / "src"))

import torch
from infrastructure.biometrics.local_antispoof_models import (
    LocalAASISTModel,
    build_local_model_paths
)
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def verify_aasist_l():
    """Verificar que AASIST-L se cargue desde los archivos locales."""
    
    print("="*80)
    print("VERIFICACI√ìN DE CARGA DE AASIST-L LOCAL")
    print("="*80)
    
    # Verificar archivos
    print("\n1. Verificando archivos locales...")
    local_paths = build_local_model_paths()
    aasist_dir = local_paths.aasist_dir
    
    print(f"   Directorio AASIST: {aasist_dir}")
    
    files_to_check = [
        ("AASIST-L.pth", "Checkpoint AASIST-L"),
        ("AASIST-L.conf", "Configuraci√≥n AASIST-L"),
        ("AASIST.py", "C√≥digo del modelo"),
    ]
    
    all_found = True
    for filename, description in files_to_check:
        filepath = aasist_dir / filename
        if filepath.exists():
            size_mb = filepath.stat().st_size / (1024*1024)
            print(f"   ‚úÖ {description}: {filepath.name} ({size_mb:.1f}MB)")
        else:
            print(f"   ‚ùå {description}: {filename} NO ENCONTRADO")
            all_found = False
    
    if not all_found:
        print("\n‚ö†Ô∏è  Faltan archivos necesarios para AASIST-L")
        return False
    
    # Cargar modelo
    print("\n2. Intentando cargar AASIST-L...")
    try:
        device = torch.device("cpu")
        model = LocalAASISTModel(device=device, paths=local_paths)
        
        if not model.available:
            print("   ‚ùå Modelo no se pudo cargar (available=False)")
            return False
        
        print(f"   ‚úÖ Modelo {model._model_name} cargado exitosamente")
        print(f"   üìè Target length: {model._target_len}")
        
        # Probar predicci√≥n
        print("\n3. Probando predicci√≥n con audio dummy...")
        dummy_audio = torch.randn(1, 16000)  # 1 segundo
        
        score = model.predict_spoof_probability(dummy_audio, 16000)
        
        if score is not None:
            print(f"   ‚úÖ Predicci√≥n exitosa!")
            print(f"   üìä Score de prueba: {score:.4f}")
            print(f"      (0.0 = genuino, 1.0 = spoofed)")
            
            print("\n" + "="*80)
            print("‚úÖ AASIST-L SE CARG√ì Y FUNCIONA CORRECTAMENTE")
            print("="*80)
            return True
        else:
            print("   ‚ùå La predicci√≥n retorn√≥ None")
            return False
            
    except Exception as e:
        print(f"   ‚ùå Error al cargar modelo: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = verify_aasist_l()
    
    if success:
        print("\n‚úÖ El sistema est√° listo para usar AASIST-L")
        print("   Los siguientes componentes usar√°n autom√°ticamente AASIST-L:")
        print("   - SpoofDetectorAdapter")
        print("   - Scripts de evaluaci√≥n")
        print("   - API de verificaci√≥n biom√©trica")
    else:
        print("\n‚ö†Ô∏è  El sistema usar√° el modelo AASIST base o fallback de SpeechBrain")
